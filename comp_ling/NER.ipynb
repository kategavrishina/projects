{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2_NER.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMayycnAgBXjmVLFtEcXIUq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUs6zBOPFir"
      },
      "source": [
        "# **Beauty продукты**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeCVF7PMR8qy"
      },
      "source": [
        "Предложите 3 способа найти упоминания товаров в отзывах. Например, использовать bootstrapping: составить шаблоны вида \"холодильник XXX\", найти все соответствующие n-граммы и выделить из них называние товара. Могут помочь заголовки и дополнительные данные с Amazon (Metadata здесь) Какие данные необходимы для каждого из способов? Какие есть достоинства/недостатки?\n",
        "\n",
        "Реализуйте один из предложенных вами способов.\n",
        "\n",
        "Соберите n-граммы с полученными сущностями (NE + левый сосед / NE + правый сосед)\n",
        "\n",
        "Ранжируйте n-граммы с помощью 3 коллокационных метрик (t-score, PMI и т.д.). Не забудьте про частотный фильтр / сглаживание. Выберите лучший результат (какая метрика ранжирует выше коллокации, подходящие для отчёта).\n",
        "\n",
        "Сгруппируйте полученные коллокации по NE, выведите примеры для 5 товаров. Должны получиться примерно такие группы:\n",
        "\n",
        "watch \n",
        "--- \n",
        "stylish watch\n",
        "\n",
        "good watches\n",
        "\n",
        "great watch\n",
        "\n",
        "love this watch\n",
        "... *Курсив*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjiLfkD3LYde"
      },
      "source": [
        "**Способы найти упоминания товаров в отзывах:**\n",
        "\n",
        "\n",
        "1. Правиловый подход на основе шаблонов типа \"мыло Х\", \"духи Y\" и подобных, получится что-то вроде словаря основных слов для поиска. Словарь можно расширить при помощи эмбеддингов - найти ближайшие синонимы. Для этого понадобится только почистить тексты и \"пройтись\" по ним этими шаблонами. Потом надо будет из шаблонов выделить само название/NE. Достоинства: довольно просто и быстро, как раз тексты одной тематики и предметная область ограничена. Недостаток: в отзывах очень редко встречаются названия товаров, все пишут только \"этот продукт\", \"это\" и т.п + далеко не всегда после слов \"мыло\", \"духи\" и т.п. будет идти название товара.\n",
        "2. Выделить кандидатов в NE (например, именные группы), а потом их классифицировать, опираясь, например, на грамматические признаки, символьные признаки или контекст. Достоинства: с таким количеством доп. признаков и хорошей моделью классификации, скорее всего, должно быть высокое качество. Недостатки: такой подход может сильно зависеть от тематики и формы текстов, выделять тщательно кандидатов долго и трудно, а также подбирать подходящую модель классификации.\n",
        "3. Разметка последовательности: каждое слово как бы воспринимается как кандидат в NE, то есть размечаются все входные токены (как NE или не NE, или с использованием BIO-разметки: начало, середина, конец NE). Достоинства: на выходе получаем больше информации, чем в других методах. Недостатки: сложность модели, мне кажется. \n",
        "4. Можно использовать специальные инструменты для распознавания сущностей (например, natasha\\yargy), которые, скорее всего, достаточно точно выделят названия товаров. Достоинства: на среднестатистических текстах наташа работает достаточно хорошо, ее можно менять в процессе и подстраивать под задачу. Недостатки: в отзывах опять же очень мало упоминаний конкретных названий + возможно, понадобятся свои правила.\n",
        "\n",
        "Для всех этих подходов необходимы просто тексты и для некоторых дополнительно полученные значения признаков типа POS-тэга или данных о заглавной букве в начале слова.\n",
        "\n",
        "А ещё везде можно смотреть на заголовки! Там всегда есть название товара.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLZXLKdNl95b"
      },
      "source": [
        "Я хочу попробовать взять слова из заголовков (названий товаров) и к ним уже применить расширение, добавив ближайших слов с помощью эмбеддингов. Данные использую не все, оставила 10000 отзывов (всю выборку перемешала и обрезала)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NC-NEfwWXIb"
      },
      "source": [
        "Читалка данных, преобразуем в датафрейм с нужными нам полями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZrYrTq2LaY_"
      },
      "source": [
        "with open('Beauty_crop.txt', 'r', encoding='utf-8') as f:\n",
        "    all_data = f.read()\n",
        "    reviews = all_data.split('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ZoGHFinsif"
      },
      "source": [
        "import pandas as pd\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0z8K9weLac0",
        "outputId": "3b8bf9c2-88a6-46bd-a4df-6fc02aed57ee"
      },
      "source": [
        "df = pd.DataFrame(columns=['id', 'title', 'text'])\n",
        "for review in tqdm.tqdm(reviews):\n",
        "    review = review.split('\\n')\n",
        "    df.loc[len(df)] = [review[0].split(':', 1)[1].strip(), review[1].split(':', 1)[1].strip(), review[-1].split(':', 1)[1].strip()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:33<00:00, 295.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1e8jj91kPG8"
      },
      "source": [
        "К сожалению, данные ещё пришлось обрезать, потому что дальнейшие функции работают неприлично долго."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_npaHu1ckZsl"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hptQsjvokOdT"
      },
      "source": [
        "df = df.sample(3000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlOGEEpiLae_"
      },
      "source": [
        "df.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "aiO8W9-Ck9zH",
        "outputId": "7541d03c-056c-4371-cb09-2bc5ee3f082c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0009OAHIW</td>\n",
              "      <td>Dolce &amp; Gabbana Light Blue</td>\n",
              "      <td>I bought this because it was considerably chea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000GHWX34</td>\n",
              "      <td>D &amp; G Light Blue By Dolce &amp; Gabbana For Women....</td>\n",
              "      <td>Light Blue is a glorious scent, based in apple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0001TSIR2</td>\n",
              "      <td>Dr. Bronner'S Organic Bar Soaps Pure Castile</td>\n",
              "      <td>If you want to use a natural soap that leaves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000EB8CLE</td>\n",
              "      <td>Neutrogena Rainbath Refreshing Shower and Bath...</td>\n",
              "      <td>When I ordered this product I was expecting th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0007URYFM</td>\n",
              "      <td>Boundaries</td>\n",
              "      <td>This book is published by Zondervan; there are...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                               text\n",
              "0  B0009OAHIW  ...  I bought this because it was considerably chea...\n",
              "1  B000GHWX34  ...  Light Blue is a glorious scent, based in apple...\n",
              "2  B0001TSIR2  ...  If you want to use a natural soap that leaves ...\n",
              "3  B000EB8CLE  ...  When I ordered this product I was expecting th...\n",
              "4  B0007URYFM  ...  This book is published by Zondervan; there are...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIHmaJioWfS_"
      },
      "source": [
        "Чистим заголовки и тексты от пунктуации и стоп-слов, лемматизируем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRb4cn-4otRZ",
        "outputId": "64f2e1fc-097d-45ef-9e28-4ec87b9bb98e"
      },
      "source": [
        "import nltk \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN7nj-l4r6zR"
      },
      "source": [
        "import re\n",
        "from string import punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHqspfGuWke"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUnyufWst0OQ"
      },
      "source": [
        "english_stopwords = stopwords.words(\"english\")\n",
        "english_stopwords = english_stopwords + ['fl', 'oz', 'ml', 'ounce', 'ounces', 'pounds', 's']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RdmD7sr88u"
      },
      "source": [
        "def clean(text):\n",
        "    lemmas = []\n",
        "    reg = re.compile('[^a-zA-Z ]')\n",
        "    doc = nlp(text)\n",
        "    for tok in doc:\n",
        "        if tok.lower_ not in punctuation and tok.lower_ not in english_stopwords:\n",
        "            if tok.lemma_ == \"-PRON-\":\n",
        "                tok = tok.lower_\n",
        "            else:\n",
        "                tok = reg.sub('', tok.lemma_.lower().strip())\n",
        "            tok = tok.strip()\n",
        "            if tok != '':\n",
        "                lemmas.append(tok)\n",
        "    return ' '.join(lemmas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7QpE03VuiQ1",
        "outputId": "bd79cb25-733b-4d66-baa5-d47115b4dbfd"
      },
      "source": [
        "df.title[0], clean(df.title[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Dolce & Gabbana Light Blue', 'dolce gabbana light blue')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqHhb-X4umVk"
      },
      "source": [
        "tqdm.tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei_GV-RywXuX",
        "outputId": "a99189a3-eb52-4a50-b2a7-aed1b5b8ab63"
      },
      "source": [
        "df['clean_title'] = df['title'].progress_apply(clean)\n",
        "df['clean_text'] = df['text'].progress_apply(clean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:28<00:00, 103.99it/s]\n",
            "100%|██████████| 3000/3000 [01:01<00:00, 48.60it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "QzaxbkKhwzPH",
        "outputId": "d2ebafee-a4d6-4e58-feb8-a7741c3c4070"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0009OAHIW</td>\n",
              "      <td>Dolce &amp; Gabbana Light Blue</td>\n",
              "      <td>I bought this because it was considerably chea...</td>\n",
              "      <td>dolce gabbana light blue</td>\n",
              "      <td>buy considerably cheap usually purchase also f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000GHWX34</td>\n",
              "      <td>D &amp; G Light Blue By Dolce &amp; Gabbana For Women....</td>\n",
              "      <td>Light Blue is a glorious scent, based in apple...</td>\n",
              "      <td>g light blue dolce gabbana women deodorant spray</td>\n",
              "      <td>light blue glorious scent base apple musk jasm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0001TSIR2</td>\n",
              "      <td>Dr. Bronner'S Organic Bar Soaps Pure Castile</td>\n",
              "      <td>If you want to use a natural soap that leaves ...</td>\n",
              "      <td>dr bronner s organic bar soaps pure castile</td>\n",
              "      <td>want use natural soap leave clean without chem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000EB8CLE</td>\n",
              "      <td>Neutrogena Rainbath Refreshing Shower and Bath...</td>\n",
              "      <td>When I ordered this product I was expecting th...</td>\n",
              "      <td>neutrogena rainbath refreshing shower bath gel</td>\n",
              "      <td>order product expect regular version nothing t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0007URYFM</td>\n",
              "      <td>Boundaries</td>\n",
              "      <td>This book is published by Zondervan; there are...</td>\n",
              "      <td>boundary</td>\n",
              "      <td>book publish zondervan biblical reference cros...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                         clean_text\n",
              "0  B0009OAHIW  ...  buy considerably cheap usually purchase also f...\n",
              "1  B000GHWX34  ...  light blue glorious scent base apple musk jasm...\n",
              "2  B0001TSIR2  ...  want use natural soap leave clean without chem...\n",
              "3  B000EB8CLE  ...  order product expect regular version nothing t...\n",
              "4  B0007URYFM  ...  book publish zondervan biblical reference cros...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSksbGRotdPj"
      },
      "source": [
        "Теперь для каждого слова из (очищенного) названия попробуем добавить ближайшее слово в модели ворд2век от гугла. Из названия, потому что там наверняка встретится самая важная NE для товара."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVkX45yjWKf8"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAqSHQYoYaUq",
        "outputId": "3c724792-e55e-4a28-8e02-0273e19a0214"
      },
      "source": [
        "!gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:08, 195MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jdvT2a9Ygd7"
      },
      "source": [
        "! gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA8jsnH8YvL3"
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True, unicode_errors='replace', limit=200000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iXXhlhGjUXG"
      },
      "source": [
        "def add_similar(title):\n",
        "    thesaurus = []\n",
        "    for token in title.split():\n",
        "        thesaurus.append(token)\n",
        "        if token in model:\n",
        "            thesaurus.append(model.most_similar(token)[0][0].lower())\n",
        "    return thesaurus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZVykqoVjj_O",
        "outputId": "df229a50-b18c-420b-8e3a-212e4eae31f1"
      },
      "source": [
        "df['thesaurus'] = df['clean_title'].progress_apply(add_similar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [06:19<00:00,  7.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "CaPdyAOEnJ6e",
        "outputId": "a085acb6-fad9-4cb7-b9ee-3f9adf8daf94"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>thesaurus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0009OAHIW</td>\n",
              "      <td>Dolce &amp; Gabbana Light Blue</td>\n",
              "      <td>I bought this because it was considerably chea...</td>\n",
              "      <td>dolce gabbana light blue</td>\n",
              "      <td>buy considerably cheap usually purchase also f...</td>\n",
              "      <td>[dolce, gabbana, light, lights, blue, red]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000GHWX34</td>\n",
              "      <td>D &amp; G Light Blue By Dolce &amp; Gabbana For Women....</td>\n",
              "      <td>Light Blue is a glorious scent, based in apple...</td>\n",
              "      <td>g light blue dolce gabbana women deodorant spray</td>\n",
              "      <td>light blue glorious scent base apple musk jasm...</td>\n",
              "      <td>[g, h, light, lights, blue, red, dolce, gabban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0001TSIR2</td>\n",
              "      <td>Dr. Bronner'S Organic Bar Soaps Pure Castile</td>\n",
              "      <td>If you want to use a natural soap that leaves ...</td>\n",
              "      <td>dr bronner s organic bar soaps pure castile</td>\n",
              "      <td>want use natural soap leave clean without chem...</td>\n",
              "      <td>[dr, mr, bronner, s, €_™_s, organic, organic, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000EB8CLE</td>\n",
              "      <td>Neutrogena Rainbath Refreshing Shower and Bath...</td>\n",
              "      <td>When I ordered this product I was expecting th...</td>\n",
              "      <td>neutrogena rainbath refreshing shower bath gel</td>\n",
              "      <td>order product expect regular version nothing t...</td>\n",
              "      <td>[neutrogena, rainbath, refreshing, invigoratin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0007URYFM</td>\n",
              "      <td>Boundaries</td>\n",
              "      <td>This book is published by Zondervan; there are...</td>\n",
              "      <td>boundary</td>\n",
              "      <td>book publish zondervan biblical reference cros...</td>\n",
              "      <td>[boundary, boundaries]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                          thesaurus\n",
              "0  B0009OAHIW  ...         [dolce, gabbana, light, lights, blue, red]\n",
              "1  B000GHWX34  ...  [g, h, light, lights, blue, red, dolce, gabban...\n",
              "2  B0001TSIR2  ...  [dr, mr, bronner, s, €_™_s, organic, organic, ...\n",
              "3  B000EB8CLE  ...  [neutrogena, rainbath, refreshing, invigoratin...\n",
              "4  B0007URYFM  ...                             [boundary, boundaries]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR0X1EIvttUz"
      },
      "source": [
        "Теперь будем выделять нграммы (ближайшие соседи слева и справа, так как они показались мне наиболее значимыми: например, \"лучшее мыло\" или \"мыло прекрасно\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eh9j8QEpfNv"
      },
      "source": [
        "def ngrams(text, thesaurus):\n",
        "    ngrams = {}\n",
        "    text = text.split()\n",
        "    for i, token in enumerate(text):\n",
        "        if token in thesaurus:\n",
        "            ngrams[token] = []\n",
        "            if i != 0:\n",
        "                ngrams[token].append(text[i-1] + ' ' + token)\n",
        "            if i+1 != len(text):\n",
        "                ngrams[token].append(token + ' ' + text[i+1])\n",
        "    return ngrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YLG4k0qq0XL",
        "outputId": "480dbbf5-daf1-4211-f4e9-d0b43e43cd5c"
      },
      "source": [
        "df['ngrams'] = df[['clean_text', 'thesaurus']].progress_apply(lambda row: ngrams(row['clean_text'], row['thesaurus']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 3000/3000 [00:00<00:00, 32297.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "4cn5uHfcsvzt",
        "outputId": "4ca5c7fe-4754-4345-aa36-33a816d1ec05"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>thesaurus</th>\n",
              "      <th>ngrams</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0009OAHIW</td>\n",
              "      <td>Dolce &amp; Gabbana Light Blue</td>\n",
              "      <td>I bought this because it was considerably chea...</td>\n",
              "      <td>dolce gabbana light blue</td>\n",
              "      <td>buy considerably cheap usually purchase also f...</td>\n",
              "      <td>[dolce, gabbana, light, lights, blue, red]</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000GHWX34</td>\n",
              "      <td>D &amp; G Light Blue By Dolce &amp; Gabbana For Women....</td>\n",
              "      <td>Light Blue is a glorious scent, based in apple...</td>\n",
              "      <td>g light blue dolce gabbana women deodorant spray</td>\n",
              "      <td>light blue glorious scent base apple musk jasm...</td>\n",
              "      <td>[g, h, light, lights, blue, red, dolce, gabban...</td>\n",
              "      <td>{'light': ['spray light', 'light enough'], 'bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0001TSIR2</td>\n",
              "      <td>Dr. Bronner'S Organic Bar Soaps Pure Castile</td>\n",
              "      <td>If you want to use a natural soap that leaves ...</td>\n",
              "      <td>dr bronner s organic bar soaps pure castile</td>\n",
              "      <td>want use natural soap leave clean without chem...</td>\n",
              "      <td>[dr, mr, bronner, s, €_™_s, organic, organic, ...</td>\n",
              "      <td>{'soap': ['brand soap', 'soap miss']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000EB8CLE</td>\n",
              "      <td>Neutrogena Rainbath Refreshing Shower and Bath...</td>\n",
              "      <td>When I ordered this product I was expecting th...</td>\n",
              "      <td>neutrogena rainbath refreshing shower bath gel</td>\n",
              "      <td>order product expect regular version nothing t...</td>\n",
              "      <td>[neutrogena, rainbath, refreshing, invigoratin...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0007URYFM</td>\n",
              "      <td>Boundaries</td>\n",
              "      <td>This book is published by Zondervan; there are...</td>\n",
              "      <td>boundary</td>\n",
              "      <td>book publish zondervan biblical reference cros...</td>\n",
              "      <td>[boundary, boundaries]</td>\n",
              "      <td>{'boundary': ['talk boundary']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                             ngrams\n",
              "0  B0009OAHIW  ...                                                 {}\n",
              "1  B000GHWX34  ...  {'light': ['spray light', 'light enough'], 'bl...\n",
              "2  B0001TSIR2  ...              {'soap': ['brand soap', 'soap miss']}\n",
              "3  B000EB8CLE  ...                                                 {}\n",
              "4  B0007URYFM  ...                    {'boundary': ['talk boundary']}\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6uHH4-jx9q1"
      },
      "source": [
        "Решила дальше все смотреть и демонстрировать на примере топ-10 самых представленных в выборке продуктов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BktkxIg2uqs7",
        "outputId": "03487b3f-2538-4706-a509-d94e2cb96d9f"
      },
      "source": [
        "most_represented = []\n",
        "groups = df.groupby('id')\n",
        "for k, v in sorted(groups.groups.items(), key=(lambda kv: len(kv[1])), reverse=True)[:10]:\n",
        "    most_represented.append(k)\n",
        "    print(k, v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B0009V1YR8 Int64Index([  53,   54,  272,  399,  441,  550,  563,  596,  621,  652,  674,\n",
            "             700, 1106, 1396, 1452, 1472, 1507, 1687, 1688, 1691, 1738, 1777,\n",
            "            1893, 2162, 2195, 2291, 2376, 2438, 2562, 2602, 2715, 2780, 2793,\n",
            "            2852, 2898, 2982, 2985, 2995],\n",
            "           dtype='int64')\n",
            "B0000YUXI0 Int64Index([ 181,  257,  348,  898, 1238, 1371, 1382, 1420, 1690, 1811, 2016,\n",
            "            2160, 2540, 2559, 2644, 2773],\n",
            "           dtype='int64')\n",
            "B00011JL6W Int64Index([ 500,  508,  541,  715,  725,  777, 1399, 1441, 2097, 2254, 2426,\n",
            "            2495, 2592, 2671, 2977],\n",
            "           dtype='int64')\n",
            "B0000533G8 Int64Index([325, 559, 661, 1277, 1477, 1566, 1603, 1785, 2199, 2427, 2657,\n",
            "            2875],\n",
            "           dtype='int64')\n",
            "B00011JKS6 Int64Index([336, 538, 847, 1320, 1361, 1379, 1408, 1765, 1854, 2642], dtype='int64')\n",
            "B00011JM66 Int64Index([5, 281, 289, 448, 1039, 1322, 1509, 1538, 1834, 1877], dtype='int64')\n",
            "B00021DVCQ Int64Index([228, 571, 655, 766, 948, 1107, 1349, 2446, 2513, 2979], dtype='int64')\n",
            "B0002JKPB8 Int64Index([92, 332, 392, 667, 1484, 1650, 1871, 2007, 2766], dtype='int64')\n",
            "B0002SGRD4 Int64Index([142, 391, 1080, 1244, 1286, 1397, 1565, 2491, 2593], dtype='int64')\n",
            "B00005A441 Int64Index([32, 173, 436, 1381, 1551, 1898, 1961, 2080], dtype='int64')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTMfv1np-erD"
      },
      "source": [
        "Дальше посмотрим на коллокации. Так как самих биграмм было найдено очень мало для запуска такого ранжирования, я решила посмотреть на эти метрики с точки зрения ранжирования коллокаций из всех очищенных текстов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENfUXlNuwEhs"
      },
      "source": [
        "import nltk\n",
        "from nltk.collocations import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njrw1wVL0TxR"
      },
      "source": [
        "bigram_measures = nltk.collocations.BigramAssocMeasures()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AtYwU3RyQPm"
      },
      "source": [
        "finder = BigramCollocationFinder.from_documents(df['clean_text'].apply(lambda text: text.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG1iDBPIyQS_",
        "outputId": "dbe39d67-404a-40d1-c621-691a1b7d39be"
      },
      "source": [
        "finder.score_ngrams(bigram_measures.pmi)[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('aaaa', 'aaa'), 16.726444361120034),\n",
              " (('ademas', 'rinde'), 16.726444361120034),\n",
              " (('advance', 'trish'), 16.726444361120034),\n",
              " (('aesthetic', 'atrocious'), 16.726444361120034),\n",
              " (('aire', 'libre'), 16.726444361120034),\n",
              " (('airplane', 'fuel'), 16.726444361120034),\n",
              " (('allof', 'friz'), 16.726444361120034),\n",
              " (('amanda', 'richards'), 16.726444361120034),\n",
              " (('ambree', 'legrain'), 16.726444361120034),\n",
              " (('ammonia', 'resorcinol'), 16.726444361120034),\n",
              " (('amusement', 'park'), 16.726444361120034),\n",
              " (('animalprotect', 'foeswho'), 16.726444361120034),\n",
              " (('antioxidants', 'vitamins'), 16.726444361120034),\n",
              " (('ao', 'propoacutesito'), 16.726444361120034),\n",
              " (('aproveacutechenla', 'pasas'), 16.726444361120034),\n",
              " (('aquellas', 'persona'), 16.726444361120034),\n",
              " (('arbonne', 'dhc'), 16.726444361120034),\n",
              " (('argentina', 'uruguay'), 16.726444361120034),\n",
              " (('articulo', 'inmediatamentele'), 16.726444361120034),\n",
              " (('ashe', 'cinder'), 16.726444361120034)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ZLhjcV-gEf",
        "outputId": "d8cb62e8-b4bb-4522-bbb0-a21bb8347b38"
      },
      "source": [
        "finder.score_ngrams(bigram_measures.student_t)[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('can', 'not'), 12.375255885976804),\n",
              " (('have', 'use'), 10.84743091462316),\n",
              " (('use', 'product'), 10.070163717813214),\n",
              " (('work', 'well'), 10.04846144581766),\n",
              " (('highly', 'recommend'), 9.755933301085491),\n",
              " (('nail', 'polish'), 9.099427219518239),\n",
              " (('year', 'ago'), 9.029581982216827),\n",
              " (('would', 'recommend'), 8.671041103723036),\n",
              " (('will', 'not'), 8.537868360276534),\n",
              " (('smell', 'like'), 8.432134489553093),\n",
              " (('not', 'know'), 8.4097002906281),\n",
              " (('first', 'time'), 8.115156167151362),\n",
              " (('long', 'time'), 8.092364450648814),\n",
              " (('dry', 'skin'), 8.038332624547627),\n",
              " (('great', 'product'), 7.992714361722389),\n",
              " (('recommend', 'product'), 7.969880548681493),\n",
              " (('work', 'great'), 7.810082531413461),\n",
              " (('feel', 'like'), 7.693948554130004),\n",
              " (('hair', 'dryer'), 7.587115771252509),\n",
              " (('really', 'like'), 7.544499029331948)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QXkkg43yQWP",
        "outputId": "96399931-e1fe-4e6e-cf22-68eca1e520ba"
      },
      "source": [
        "finder.score_ngrams(bigram_measures.likelihood_ratio)[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('can', 'not'), 1308.8268085489924),\n",
              " (('highly', 'recommend'), 995.3886084417711),\n",
              " (('nail', 'polish'), 725.771367148112),\n",
              " (('year', 'ago'), 696.5863644655271),\n",
              " (('china', 'glaze'), 568.2872731537924),\n",
              " (('flat', 'iron'), 560.9997062062223),\n",
              " (('work', 'well'), 520.5664165248829),\n",
              " (('have', 'use'), 506.977082820252),\n",
              " (('sensitive', 'skin'), 415.06004824745446),\n",
              " (('would', 'recommend'), 405.2537357914656),\n",
              " (('will', 'not'), 395.72501480321444),\n",
              " (('top', 'coat'), 382.9624267769837),\n",
              " (('curl', 'iron'), 380.4078893852437),\n",
              " (('every', 'day'), 377.7509954714794),\n",
              " (('first', 'time'), 376.6704244904686),\n",
              " (('long', 'time'), 363.492655885527),\n",
              " (('year', 'old'), 352.25179642388497),\n",
              " (('eau', 'de'), 347.4735625934911),\n",
              " (('not', 'know'), 338.05231154865),\n",
              " (('little', 'bit'), 332.4896308604349)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accYxKoA-8lL"
      },
      "source": [
        "Мне кажется, что метрика с критерием Стьюдента и метрика с функцией правдоподобия оказались очень похожи по результатам -- они выделяют те коллокации, которые фактически являются названиями товаров (возможно, в биграммах они просто не так широко представлены, если смотреть на них в рамках одного продукта): например, nail polish и top coat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huaxuzgi9l1h"
      },
      "source": [
        "Вывожу все найденные биграммы для каждого слова из словаря для каждго из наиболее представленных продуктов (один продукт повторяется, так как почему-то у него разные айди)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4-JvPxZ5ox7",
        "outputId": "9bfe9d02-172e-4dd8-f007-4e7d041bf0fe"
      },
      "source": [
        "for key, value in groups.groups.items():\n",
        "    if key in most_represented:\n",
        "        bigrams_for_product = {}\n",
        "        for index in value:\n",
        "            bigrams = df['ngrams'][index]\n",
        "            for word, ngram_list in bigrams.items():\n",
        "                if word in bigrams_for_product:\n",
        "                    bigrams_for_product[word] += ngram_list\n",
        "                else:\n",
        "                    bigrams_for_product[word] = []\n",
        "        print(df[df.id == key].iloc[0]['title'], '\\n')\n",
        "        for key, value in bigrams_for_product.items():\n",
        "            if len(value) > 0:\n",
        "                print(key, '\\n____________\\n', '\\n'.join(value[:5]), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dr. Bronner - Castile Soap \n",
            "\n",
            "soap \n",
            "____________\n",
            " body soap\n",
            "bronners soap\n",
            "soap need\n",
            "liquid soap\n",
            "soap please \n",
            "\n",
            "dr \n",
            "____________\n",
            " please dr\n",
            "dr bronner\n",
            "use dr\n",
            "dr bronner\n",
            "ingredient dr \n",
            "\n",
            "bronner \n",
            "____________\n",
            " dr bronner\n",
            "bronner s\n",
            "remember bronner\n",
            "bronner s\n",
            "dr bronner \n",
            "\n",
            "castile \n",
            "____________\n",
            " castile shampoo \n",
            "\n",
            "Conair CHV14JXR Extreme Heat Jumbo and Super Jumbo Rollers \n",
            "\n",
            "roller \n",
            "____________\n",
            " top roller\n",
            "roller heat\n",
            "hair roller\n",
            "roller burn\n",
            "keep roller \n",
            "\n",
            "heat \n",
            "____________\n",
            " roller heat\n",
            "heat fast\n",
            "use heat\n",
            "heat fast\n",
            "time heat \n",
            "\n",
            "conair \n",
            "____________\n",
            " think conair\n",
            "conair would\n",
            "call conair\n",
            "conair send\n",
            "purchase conair \n",
            "\n",
            "jumbo \n",
            "____________\n",
            " one jumbo\n",
            "jumbo one \n",
            "\n",
            "super \n",
            "____________\n",
            " anything super\n",
            "super long \n",
            "\n",
            "Mavala Stop - Helps Cure Nail Biting and Thumb Sucking, 0.3-Fluid Ounce \n",
            "\n",
            "stop \n",
            "____________\n",
            " mavala stop\n",
            "stop anyone\n",
            "wife stop\n",
            "stop bite\n",
            "son stop \n",
            "\n",
            "thumb \n",
            "____________\n",
            " suck thumb\n",
            "thumb anymore\n",
            "dip thumb\n",
            "thumb milk\n",
            "suck thumb \n",
            "\n",
            "mavala \n",
            "____________\n",
            " apply mavala\n",
            "mavala cry\n",
            "else mavala\n",
            "mavala stop\n",
            "put mavala \n",
            "\n",
            "suck \n",
            "____________\n",
            " daughter suck\n",
            "suck thumb\n",
            "not suck\n",
            "suck finger\n",
            "daughter suck \n",
            "\n",
            "help \n",
            "____________\n",
            " awful help\n",
            "help remind\n",
            "son help\n",
            "help stop \n",
            "\n",
            "nail \n",
            "____________\n",
            " bite nail\n",
            "nail anymore\n",
            "one nail\n",
            "nail taste\n",
            "bite nail \n",
            "\n",
            "China Glaze Nail Lacquer with Hardeners \n",
            "\n",
            "nail \n",
            "____________\n",
            " hold nail\n",
            "nail far\n",
            "love nail\n",
            "nail polish\n",
            "lot nail \n",
            "\n",
            "China Glaze Nail Lacquer with Hardeners \n",
            "\n",
            "china \n",
            "____________\n",
            " purchase china\n",
            "china glaze\n",
            "china glaze\n",
            "good china\n",
            "china glaze \n",
            "\n",
            "glaze \n",
            "____________\n",
            " china glaze\n",
            "glaze wonderful\n",
            "china glaze\n",
            "glaze deliver\n",
            "china glaze \n",
            "\n",
            "nail \n",
            "____________\n",
            " color nail\n",
            "nail salon\n",
            "stain nail\n",
            "nail blue\n",
            "stroke nail \n",
            "\n",
            "China Glaze Nail Lacquer with Hardeners \n",
            "\n",
            "nail \n",
            "____________\n",
            " stroke nail\n",
            "nail require\n",
            "use nail\n",
            "nail polish\n",
            "get nail \n",
            "\n",
            "china \n",
            "____________\n",
            " good china\n",
            "china glaze\n",
            "polish china\n",
            "china glaze\n",
            "def china \n",
            "\n",
            "glaze \n",
            "____________\n",
            " china glaze\n",
            "china glaze\n",
            "glaze collection\n",
            "china glaze\n",
            "glaze girl \n",
            "\n",
            "Bare Escentuals BareMinerals \n",
            "\n",
            "bare \n",
            "____________\n",
            " real bare\n",
            "bare mineralsbad\n",
            "realize bare\n",
            "bare minerals\n",
            "use bare \n",
            "\n",
            "Caruso Molecular Steam Hairsetter \n",
            "\n",
            "caruso \n",
            "____________\n",
            " caruso hot\n",
            "hope caruso\n",
            "caruso roller \n",
            "\n",
            "China Glaze Nail Lacquer with Hardeners \n",
            "\n",
            "nail \n",
            "____________\n",
            " stain nail\n",
            "nail blue\n",
            "stay nail\n",
            "whole nail\n",
            "nail can \n",
            "\n",
            "china \n",
            "____________\n",
            " finish china\n",
            "china glaze \n",
            "\n",
            "glaze \n",
            "____________\n",
            " china glaze\n",
            "glaze fast\n",
            "stead glaze \n",
            "\n",
            "Farouk CHI 1 Inch Ceramic Flat Hairstyling Iron \n",
            "\n",
            "farouk \n",
            "____________\n",
            " month farouk\n",
            "farouk fix\n",
            "try farouk\n",
            "farouk silk\n",
            "together farouk \n",
            "\n",
            "chi \n",
            "____________\n",
            " product chi\n",
            "chi s\n",
            "secondly chi\n",
            "chi iron\n",
            "hype chi \n",
            "\n",
            "iron \n",
            "____________\n",
            " chi iron\n",
            "iron good\n",
            "flat iron\n",
            "iron trick\n",
            "replacement iron \n",
            "\n",
            "flat \n",
            "____________\n",
            " end flat\n",
            "flat iron\n",
            "away flat\n",
            "flat iron\n",
            "old flat \n",
            "\n",
            "ceramic \n",
            "____________\n",
            " come ceramic\n",
            "ceramic plate \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RVlnAkd-Man"
      },
      "source": [
        "К сожалению, эти коллокации получились не такими красивыми, как хотелось бы. Скорее всего, так получилось из-за того, что в отзывах действительно пишут в 95% случаев \"этот продукт\" или \"это\" вместо NE. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKzTP8wskAef"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}